/**
 * üîí DOCUMENT SYSTEM LOCKDOWN - AUTHORIZATION REQUIRED
 * This file is protected under Document System Lockdown Policy
 * NO MODIFICATIONS without explicit owner authorization
 * Policy Date: July 17, 2025
 * Contact: System Owner for change requests
 */

import { promises as fs } from 'fs';
import path from 'path';
import { v4 as uuid } from 'uuid';
import { db } from '../db.js';
import { documents } from '../../shared/schema.js';
import { eq, desc } from 'drizzle-orm';
import { logUpload } from './uploadLogger.js';
import { safeWriteFileAndVerify, enqueueRecoveryAlert } from './safeFileWriter.js';

const BASE_DIR = process.cwd();

/**
 * üõ°Ô∏è PERMANENT UPLOAD SYSTEM HARDENING - ROCK SOLID IMPLEMENTATION
 * 
 * PHASE 1: Unified document storage with consistent path structure
 * Every document saved to: uploads/documents/{documentId}.{ext}
 * No more applicationId folders - centralized storage
 * 
 * üö´ DO NOT ADD ABORT-BASED CLEANUP HERE
 * This upload system has been hardened against false positives.
 * Any future connection monitoring must be approved via ChatGPT review.
 * 
 * ‚ö†Ô∏è BANNED PATTERNS (DO NOT REINTRODUCE):
 * - req.aborted || req.destroyed checks
 * - req.on("close", cleanup_function)  
 * - req.on("aborted", cleanup_function)
 * - req.socket.on("error", cleanup_function)
 * 
 * ‚úÖ GUARANTEED BEHAVIORS:
 * - Every valid document reaches file system AND database
 * - No false abort detection
 * - No post-upload cleanup routines  
 * - Unconditional saves for all valid uploads
 */
export async function saveDocumentToDiskAndDB(
  applicationId: string,
  sourceFilePath: string,
  originalFileName: string,
  documentType: string,
  uploadedBy = 'system'
): Promise<string> {
  console.log(`üîß [RELIABILITY UPGRADE] Starting enhanced save process for: ${originalFileName}`);
  
  // CRITICAL: Early document type validation to prevent database enum errors
  const validDocumentTypes = [
    'accounts_payable', 'accounts_receivable', 'ap', 'ar', 'articles_of_incorporation', 
    'balance_sheet', 'bank_statements', 'business_license', 'business_plan', 'cash_flow_statement',
    'collateral_docs', 'drivers_license_front_back', 'equipment_photos', 'equipment_quote', 
    'financial_statements', 'invoice_samples', 'other', 'personal_financial_statement', 
    'personal_guarantee', 'profit_and_loss_statement', 'profit_loss_statement', 'proof_of_identity', 
    'purchase_orders', 'sba_forms', 'signed_application', 'supplier_agreement', 'tax_returns', 'void_pad'
  ];
  
  if (!validDocumentTypes.includes(documentType)) {
    console.error(`‚ùå [DOCUMENT STORAGE] Invalid document type: ${documentType}`);
    console.error(`‚ùå [DOCUMENT STORAGE] Valid types:`, validDocumentTypes);
    throw new Error(`Invalid document type: ${documentType}. Valid types: ${validDocumentTypes.join(', ')}`);
  }
  
  // Generate unique document ID FIRST
  const documentId = uuid();
  
  // Extract file extension from original filename
  const fileExt = path.extname(originalFileName).toLowerCase() || '.pdf';
  
  // UNIFIED STORAGE: All files go to uploads/documents/
  const documentsDir = path.join(BASE_DIR, 'uploads', 'documents');
  const fileName = `${documentId}${fileExt}`;
  const targetFilePath = path.join(documentsDir, fileName);
  const dbFilePath = `uploads/documents/${fileName}`;
  
  // Ensure documents directory exists
  await fs.mkdir(documentsDir, { recursive: true });
  console.log(`üìÅ [HARDENED] Directory ensured: ${documentsDir}`);

  // üìÇ STRICT COMPLIANCE: Read actual file content and get size from disk
  console.log(`üîç [SOURCE PATH DEBUG] sourceFilePath: ${sourceFilePath}`);
  console.log(`üîç [SOURCE PATH DEBUG] typeof sourceFilePath: ${typeof sourceFilePath}`);
  console.log(`üîç [SOURCE PATH DEBUG] fs.existsSync check: ${sourceFilePath ? (await fs.access(sourceFilePath).then(() => true).catch(() => false)) : 'N/A'}`);
  
  if (!sourceFilePath) {
    throw new Error(`Source file path is undefined - multer may not be saving files properly`);
  }
  
  const fileContent = await fs.readFile(sourceFilePath);
  const fileStats = await fs.stat(sourceFilePath);
  console.log(`üìÇ Saved:`, sourceFilePath, `| Size:`, fileStats.size);
  
  // ‚úÖ PHASE 3: Checksum calculation AFTER write verification
  // Note: This will be recalculated after successful disk write
  
  // üíæ DISK-ONLY MODE FOR TESTING: Skip Azure upload and use local storage
  let storageKey: string | null = null;
  
  try {
    console.log(`üîç [DISK-ONLY] Skipping Azure upload for testing - using local storage`);
    console.log(`üîç [DISK-ONLY] Document saved to disk: ${targetFilePath}`);
    
    // For testing, use the local file path as storage key
    storageKey = dbFilePath; // Use local path: uploads/documents/filename.pdf
    console.log(`üíæ [DISK-ONLY] Using local storage key: ${storageKey}`);
    
  } catch (error: unknown) {
    console.error(`‚ùå [Azure-ONLY] Amazon Azure upload failed:`, error);
    console.error(`‚ùå [Azure-ONLY] Error details:`, error instanceof Error ? error instanceof Error ? error.stack : undefined : 'Unknown error');
    
    // Only create fallback for specific Azure errors (NoSuchBucket, etc.)
    if (error instanceof Error && (error instanceof Error ? error.message : String(error).includes('NoSuchBucket') || error instanceof Error ? error.message : String(error).includes('AccessDenied'))) {
      console.warn(`‚ö†Ô∏è [Azure-FALLBACK] Azure infrastructure error - using fallback key`);
      throw new Error(`Azure upload failed - no fallback allowed for ${originalFileName}`);
    } else {
      throw error; // Re-throw other errors to fail the upload
    }
  }
  
  // üö´ Azure-ONLY MODE: Skip disk storage (files only exist in Azure)
  console.log(`üö´ [Azure-ONLY] Skipping disk storage - files exist only in Azure cloud storage`);
  console.log(`‚òÅÔ∏è [Azure-ONLY] Document accessible via Azure key: ${storageKey}`);

  // üîê COMPUTE CHECKSUM FOR Azure FILE
  const { computeChecksum } = await import('./checksumUtils.js');
  const checksum = computeChecksum(fileContent);
  console.log(`üîê [Azure-ONLY] SHA256 computed for Azure file: ${checksum}`);

  // üîí Azure-ONLY DATABASE INSERT: Store Azure key and metadata
  console.log(`üíæ [Azure-ONLY] Committing Azure document to database...`);
  try {
    console.log(`üîç [DEBUG] About to insert with storage_key: ${storageKey}`);
    
    // üîß CRITICAL FIX: Use raw SQL to avoid Drizzle ORM field mapping issues
    const { pool } = await import('../db.js');
    const insertQuery = `
      INSERT INTO documents (
        id, applicationId, name, file_path, size, 
        document_type, uploaded_by, checksum, storage_key, file_exists, createdAt
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
      RETURNING id, name, storage_key
    `;
    
    const insertResult = await pool.query(insertQuery, [
      documentId,
      applicationId,
      originalFileName,
      null, // No local file path for Azure-only mode
      fileContent.length,
      documentType,
      uploadedBy,
      checksum,
      storageKey, // Azure storage key
      true, // file_exists
      new Date()
    ]);
    
    console.log(`üîç [DEBUG] Raw SQL insert result:`, insertResult.rows[0]);
    console.log(`‚úÖ [Azure-ONLY] Database transaction committed with Azure key: ${storageKey}`);
    
  } catch (dbError: any) {
    console.error(`üö® [Azure-ONLY] Database insert failed - initiating Azure cleanup:`, dbError.message);
    
    // ROLLBACK: Remove file from Azure
    try {
      const { deleteFromAzure } = await import('../config/s3Config.js');
      if (storageKey) {
        await deleteFromAzure(storageKey);
        console.log(`üîÑ [Azure-ROLLBACK] File removed from Azure: ${storageKey}`);
      }
    } catch (s3CleanupError) {
      console.error(`‚ùå [Azure-ROLLBACK] Azure cleanup failed:`, s3CleanupError);
    }
    
    enqueueRecoveryAlert(applicationId, originalFileName);
    throw new Error(`Database insert failed after successful Azure upload: ${dbError.message}`);
  }

  // ENHANCED FEATURE 1: Create initial version record (with error handling) - DISABLED
  // Document versioning temporarily disabled due to schema compatibility issues
  console.log('üìù [VERSION] Document versioning skipped - main document saved successfully');

  // ENHANCED FEATURE 5: Log the upload
  await logUpload(documentId, uploadedBy, "success", fileContent.length, documentType);
  
  // AUDIT LOGGING: Log successful upload with checksum
  const { auditLogger } = await import('./auditLogger.js');
  await auditLogger.logUpload(documentId, originalFileName, fileContent.length, checksum);

  console.log(`üéØ [Azure-ONLY SUCCESS] Complete Azure upload successful: ${documentId} | Azure: ‚úÖ | Database: ‚úÖ`);
  return documentId;
}

/**
 * SAFETY NET: Verify document exists on disk
 */
export async function verifyDocumentOnDisk(filePath: string): Promise<boolean> {
  try {
    const fullPath = path.join(BASE_DIR, filePath);
    await fs.access(fullPath);
    console.log(`‚úÖ [Document Storage] File verified: ${filePath}`);
    return true;
  } catch {
    console.log(`‚ùå [Document Storage] File not found: ${filePath}`);
    return false;
  }
}

/**
 * SAFETY NET 2: Validate application has documents before submission
 */
export async function validateApplicationHasDocuments(applicationId: string): Promise<boolean> {
  try {
    const appDocuments = await db.select().from(documents).where(eq(documents.applicationId, applicationId));
    const hasDocuments = appDocuments.length > 0;
    
    console.log(`üìä [Document Validation] Application ${applicationId}: ${appDocuments.length} documents`);
    
    if (!hasDocuments) {
      console.warn(`‚ö†Ô∏è [Document Validation] Application ${applicationId} has no documents!`);
    }
    
    return hasDocuments;
  } catch (error: unknown) {
    console.error(`‚ùå [Document Validation] Error checking documents for app ${applicationId}:`, error);
    return false;
  }
}

/**
 * SAFETY NET 3: Prevent application deletion if documents exist
 */
export async function checkDocumentsBeforeAppDeletion(applicationId: string): Promise<{ canDelete: boolean; documentCount: number }> {
  try {
    const appDocuments = await db.select().from(documents).where(eq(documents.applicationId, applicationId));
    const documentCount = appDocuments.length;
    
    if (documentCount > 0) {
      console.warn(`üõë [Deletion Protection] Application ${applicationId} has ${documentCount} documents - deletion blocked`);
      return { canDelete: false, documentCount };
    }
    
    console.log(`‚úÖ [Deletion Protection] Application ${applicationId} safe to delete - no documents`);
    return { canDelete: true, documentCount: 0 };
  } catch (error: unknown) {
    console.error(`‚ùå [Deletion Protection] Error checking documents for app ${applicationId}:`, error);
    return { canDelete: false, documentCount: -1 };
  }
}

/**
 * REMOVED: Failed upload logging (not needed with guaranteed saves)
 * The hardened system has unconditional saves so failures are extremely rare
 */

/**
 * Check for recent upload failures and trigger admin alert if threshold exceeded
 */
export async function checkUploadFailureAlert(): Promise<{ shouldAlert: boolean; failureCount: number }> {
  try {
    const { pool } = await import('../db.js');
    const result = await pool.query(`
      SELECT COUNT(*) as failure_count 
      FROM uploads_log 
      WHERE createdAt > NOW() - INTERVAL '5 minutes'
    `);
    
    const failureCount = parseInt(result.rows[0]?.failure_count || '0');
    const shouldAlert = failureCount > 5;
    
    if (shouldAlert) {
      console.warn(`üö® [UPLOAD ALERT] ${failureCount} upload failures in last 5 minutes - admin notification required`);
    }
    
    return { shouldAlert, failureCount };
  } catch (error: unknown) {
    console.error(`‚ùå [UPLOAD ALERT] Failed to check upload failure rate: ${error}`);
    return { shouldAlert: false, failureCount: 0 };
  }
}

/**
 * SAFETY NET: Get document file buffer with unified path support
 */
export async function getDocumentFromDisk(filePath: string): Promise<Buffer> {
  console.log(`üîç [Document Storage] Retrieving file: ${filePath}`);
  
  try {
    // Primary path: unified documents directory
    const fullPath = path.join(BASE_DIR, filePath);
    console.log(`üîç [Document Storage] Trying primary path: ${fullPath}`);
    
    if (await fs.access(fullPath).then(() => true).catch(() => false)) {
      console.log(`‚úÖ [Document Storage] Found at primary path: ${fullPath}`);
      return await fs.readFile(fullPath);
    }
    
    // If primary path fails, try comprehensive fallback search
    console.log(`üîç [Document Storage] Primary path failed, searching alternative locations...`);
    
    // Extract document ID from path (assuming format: uploads/documents/{id}.pdf)
    const documentId = path.basename(filePath, path.extname(filePath));
    const extension = path.extname(filePath);
    
    // Alternative paths to search (including application-specific folders)
    const alternativePaths = [
      // Try document ID subfolder patterns
      path.join(BASE_DIR, 'uploads', documentId, `${documentId}${extension}`),
      path.join(BASE_DIR, 'uploads', 'applications', documentId, `${documentId}${extension}`),
      path.join(BASE_DIR, 'uploads', 'documents', documentId, `${documentId}${extension}`)
    ];
    
    // Search all application folders for the document
    try {
      const uploadsDir = path.join(BASE_DIR, 'uploads');
      const dirs = await fs.readdir(uploadsDir, { withFileTypes: true });
      
      for (const dir of dirs) {
        if (dir.isDirectory() && dir.name !== 'documents') {
          // Try to find any file that contains the document ID in application folders
          const appFolderPath = path.join(uploadsDir, dir.name);
          try {
            const files = await fs.readdir(appFolderPath);
            const matchingFile = files.find(file => 
              file.includes(documentId) || 
              file.endsWith(extension) && path.basename(file, extension) === documentId
            );
            
            if (matchingFile) {
              alternativePaths.push(path.join(appFolderPath, matchingFile));
            }
          } catch (dirError) {
            // Continue searching other directories
          }
        }
      }
    } catch (searchError) {
      console.log(`üîç [Document Storage] Could not search upload directories: ${searchError.message}`);
    }
    
    // Try all alternative paths
    for (const altPath of alternativePaths) {
      console.log(`üîç [Document Storage] Trying alternative path: ${altPath}`);
      if (await fs.access(altPath).then(() => true).catch(() => false)) {
        console.log(`‚úÖ [Document Storage] Found at alternative path: ${altPath}`);
        return await fs.readFile(altPath);
      }
    }
    
    // Final fallback: Check if any files exist with similar names or in any subdirectory
    console.log(`üîç [Document Storage] Performing final comprehensive search...`);
    try {
      const result = await findDocumentAnywhere(documentId, extension);
      if (result) {
        console.log(`‚úÖ [Document Storage] Found via comprehensive search: ${result}`);
        return await fs.readFile(result);
      }
    } catch (searchError) {
      console.log(`üîç [Document Storage] Comprehensive search failed: ${searchError.message}`);
    }
    
    throw new Error(`Document file not found at any location after comprehensive search`);
  } catch (error: unknown) {
    console.error(`‚ùå Failed to read document from disk: ${filePath}`, error);
    throw new Error(`Document file not found on disk: ${filePath}`);
  }
}

/**
 * Comprehensive search for document anywhere in uploads directory
 */
async function findDocumentAnywhere(documentId: string, extension: string): Promise<string | null> {
  try {
    const uploadsDir = path.join(BASE_DIR, 'uploads');
    
    // Recursive search function
    const searchDirectory = async (dir: string): Promise<string | null> => {
      try {
        const entries = await fs.readdir(dir, { withFileTypes: true });
        
        for (const entry of entries) {
          const fullPath = path.join(dir, entry.name);
          
          if (entry.isFile()) {
            // Check if filename contains the document ID
            if (entry.name.includes(documentId) || 
                path.basename(entry.name, path.extname(entry.name)) === documentId) {
              return fullPath;
            }
          } else if (entry.isDirectory()) {
            // Recursively search subdirectories
            const found = await searchDirectory(fullPath);
            if (found) return found;
          }
        }
        return null;
      } catch (err) {
        return null;
      }
    };
    
    return await searchDirectory(uploadsDir);
  } catch (error: unknown) {
    console.log(`üîç [Document Storage] Comprehensive search error: ${error instanceof Error ? error.message : String(error)}`);
    return null;
  }
}

/**
 * Standardized Document Types from Lender Product Requirements
 * Must match frontend DOCUMENT_CATEGORIES exactly
 */
export const DOCUMENT_TYPES = {
  ACCOUNTS_PAYABLE: 'accounts_payable',
  ACCOUNTS_RECEIVABLE: 'accounts_receivable',
  ARTICLES_OF_INCORPORATION: 'articles_of_incorporation',
  BALANCE_SHEET: 'balance_sheet',
  BANK_STATEMENTS: 'bank_statements',
  BUSINESS_LICENSE: 'business_license',
  BUSINESS_PLAN: 'business_plan',
  CASH_FLOW_STATEMENT: 'cash_flow_statement',
  COLLATERAL_DOCS: 'collateral_docs',
  DRIVERS_LICENSE_FRONT_BACK: 'drivers_license_front_back',
  EQUIPMENT_QUOTE: 'equipment_quote',
  FINANCIAL_STATEMENTS: 'financial_statements',
  INVOICE_SAMPLES: 'invoice_samples',
  OTHER: 'other',
  PERSONAL_FINANCIAL_STATEMENT: 'personal_financial_statement',
  PERSONAL_GUARANTEE: 'personal_guarantee',
  PROFIT_LOSS_STATEMENT: 'profit_loss_statement',
  PROOF_OF_IDENTITY: 'proof_of_identity',
  SIGNED_APPLICATION: 'signed_application',
  SUPPLIER_AGREEMENT: 'supplier_agreement',
  TAX_RETURNS: 'tax_returns',
  VOID_PAD: 'void_pad'
} as const;

// Valid document types array for validation
export const VALID_DOCUMENT_TYPES = Object.values(DOCUMENT_TYPES);

// Validation function
export function isValidDocumentType(documentType: string): boolean {
  return VALID_DOCUMENT_TYPES.includes(documentType as any);
}

/**
 * Generate timestamped filename
 */
export function generateTimestampedFileName(originalName: string, prefix?: string): string {
  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
  const extension = path.extname(originalName);
  const baseName = path.basename(originalName, extension);
  const prefixPart = prefix ? `${prefix}_` : '';
  return `${prefixPart}${baseName}_${timestamp}${extension}`;
}

/**
 * ENHANCED FEATURE 2: Object Storage Functions
 */
export async function uploadToStorage(filePath: string, storageKey: string): Promise<string> {
  try {
    // Mock object storage for development
    console.log(`‚òÅÔ∏è [OBJECT STORAGE] Uploading ${filePath} with key: ${storageKey}`);
    return `storage_${Date.now()}_${path.basename(storageKey)}`;
  } catch (error: unknown) {
    console.error("Error uploading to object storage:", error);
    throw error;
  }
}

export async function getStorageStream(storageKey: string): Promise<any> {
  try {
    // Mock storage stream for development
    console.log(`‚òÅÔ∏è [OBJECT STORAGE] Getting stream for key: ${storageKey}`);
    return fs.createReadStream('/dev/null'); // Mock stream
  } catch (error: unknown) {
    console.error("Error getting storage stream:", error);
    throw error;
  }
}

export async function deleteFromStorage(storageKey: string): Promise<void> {
  try {
    console.log(`‚òÅÔ∏è [OBJECT STORAGE] Deleting key: ${storageKey}`);
    // Mock deletion - in production would delete from object storage
  } catch (error: unknown) {
    console.error("Error deleting from storage:", error);
  }
}

/**
 * ENHANCED FEATURE 1: Create document version record
 */
export // Document versioning function DISABLED due to schema compatibility issues
// This functionality has been temporarily removed for system stability

async function getNextVersionNumber(documentId: string): Promise<number> {
  // Document versions temporarily disabled during schema migration
  console.log('Document version numbering disabled during schema migration');
  return 1;
}